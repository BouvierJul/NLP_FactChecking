{
    "LogisticRegression_CLAIM": {
        "0": {
            "precision": 0.5096153846153846,
            "recall": 0.6404833836858006,
            "f1-score": 0.5676037483266398,
            "support": 331
        },
        "1": {
            "precision": 0.8,
            "recall": 0.7,
            "f1-score": 0.7466666666666666,
            "support": 680
        },
        "accuracy": 0.6805143422354105,
        "macro avg": {
            "precision": 0.6548076923076923,
            "recall": 0.6702416918429003,
            "f1-score": 0.6571352074966532,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.7049284790382713,
            "recall": 0.6805143422354105,
            "f1-score": 0.6880417151626618,
            "support": 1011
        }
    },
    "LogisticRegression_CLAIM_META": {
        "0": {
            "precision": 0.572972972972973,
            "recall": 0.6404833836858006,
            "f1-score": 0.6048502139800287,
            "support": 331
        },
        "1": {
            "precision": 0.8143525741029641,
            "recall": 0.7676470588235295,
            "f1-score": 0.7903103709311128,
            "support": 680
        },
        "accuracy": 0.7260138476755688,
        "macro avg": {
            "precision": 0.6936627735379686,
            "recall": 0.704065221254665,
            "f1-score": 0.6975802924555707,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.7353252269476456,
            "recall": 0.7260138476755688,
            "f1-score": 0.7295909723645363,
            "support": 1011
        }
    },
    "LogisticRegression_CLAIM_META_EVIDENCE": {
        "0": {
            "precision": 0.5955678670360111,
            "recall": 0.649546827794562,
            "f1-score": 0.6213872832369942,
            "support": 331
        },
        "1": {
            "precision": 0.8215384615384616,
            "recall": 0.7852941176470588,
            "f1-score": 0.8030075187969925,
            "support": 680
        },
        "accuracy": 0.7408506429277942,
        "macro avg": {
            "precision": 0.7085531642872362,
            "recall": 0.7174204727208104,
            "f1-score": 0.7121974010169934,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.7475560018151073,
            "recall": 0.7408506429277942,
            "f1-score": 0.7435453051764589,
            "support": 1011
        }
    },
    "LSTM_CLAIM_META": {
        "0": {
            "precision": 0.5968379446640316,
            "recall": 0.4561933534743202,
            "f1-score": 0.5171232876712328,
            "support": 331
        },
        "1": {
            "precision": 0.762532981530343,
            "recall": 0.85,
            "f1-score": 0.8038942976356049,
            "support": 680
        },
        "accuracy": 0.7210682492581603,
        "macro avg": {
            "precision": 0.6796854630971874,
            "recall": 0.6530966767371601,
            "f1-score": 0.6605087926534189,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.708284655909424,
            "recall": 0.7210682492581603,
            "f1-score": 0.7100058660844603,
            "support": 1011
        }
    },
    "LSTM_CLAIM": {
        "0": {
            "precision": 0.5467980295566502,
            "recall": 0.33534743202416917,
            "f1-score": 0.41573033707865165,
            "support": 331
        },
        "1": {
            "precision": 0.7277227722772277,
            "recall": 0.8647058823529412,
            "f1-score": 0.7903225806451614,
            "support": 680
        },
        "accuracy": 0.6913946587537092,
        "macro avg": {
            "precision": 0.6372604009169389,
            "recall": 0.6000266571885552,
            "f1-score": 0.6030264588619065,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.6684882620492246,
            "recall": 0.6913946587537092,
            "f1-score": 0.667681598824672,
            "support": 1011
        }
    },
    "LSTM_CLAIM_META_EVIDENCE": {
        "0": {
            "precision": 0.5612648221343873,
            "recall": 0.42900302114803623,
            "f1-score": 0.48630136986301364,
            "support": 331
        },
        "1": {
            "precision": 0.7506596306068601,
            "recall": 0.836764705882353,
            "f1-score": 0.7913769123783032,
            "support": 680
        },
        "accuracy": 0.7032640949554896,
        "macro avg": {
            "precision": 0.6559622263706237,
            "recall": 0.6328838635151945,
            "f1-score": 0.6388391411206584,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.6886520325807588,
            "recall": 0.7032640949554896,
            "f1-score": 0.691495602217511,
            "support": 1011
        }
    },
    "RoBERTa_CLAIM": {
        "0": {
            "precision": 0.5945945945945946,
            "recall": 0.7311178247734139,
            "f1-score": 0.6558265582655827,
            "support": 331
        },
        "1": {
            "precision": 0.8526490066225165,
            "recall": 0.7573529411764706,
            "f1-score": 0.8021806853582554,
            "support": 680
        },
        "accuracy": 0.7487636003956478,
        "macro avg": {
            "precision": 0.7236218006085555,
            "recall": 0.7442353829749422,
            "f1-score": 0.729003621811919,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.7681623494699525,
            "recall": 0.7487636003956478,
            "f1-score": 0.7542645468145613,
            "support": 1011
        }
    },
    "RoBERTa_CLAIM_META": {
        "0": {
            "precision": 0.6128205128205129,
            "recall": 0.7220543806646526,
            "f1-score": 0.6629680998613037,
            "support": 331
        },
        "1": {
            "precision": 0.8518518518518519,
            "recall": 0.7779411764705882,
            "f1-score": 0.8132205995388163,
            "support": 680
        },
        "accuracy": 0.7596439169139466,
        "macro avg": {
            "precision": 0.7323361823361824,
            "recall": 0.7499977785676204,
            "f1-score": 0.73809434970006,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.7735933224558348,
            "recall": 0.7596439169139466,
            "f1-score": 0.7640281392091856,
            "support": 1011
        }
    },
    "RoBERTa_CLAIM_META_EVIDENCE": {
        "0": {
            "precision": 0.614406779661017,
            "recall": 0.8761329305135952,
            "f1-score": 0.7222914072229142,
            "support": 331
        },
        "1": {
            "precision": 0.9239332096474954,
            "recall": 0.7323529411764705,
            "f1-score": 0.8170631665299426,
            "support": 680
        },
        "accuracy": 0.7794263105835806,
        "macro avg": {
            "precision": 0.7691699946542562,
            "recall": 0.8042429358450329,
            "f1-score": 0.7696772868764283,
            "support": 1011
        },
        "weighted avg": {
            "precision": 0.8225946850920806,
            "recall": 0.7794263105835806,
            "f1-score": 0.786035023769679,
            "support": 1011
        }
    }
}